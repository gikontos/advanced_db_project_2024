{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c8305e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5808983b-dfce-4a68-b7bb-ee7a9589dd06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('adult', 121093), ('young adult', 38703), ('child', 10830), ('old', 5985)]\n",
      "Time taken: 28.52 seconds"
     ]
    }
   ],
   "source": [
    "###query 1 RDD\n",
    "\n",
    "import csv,time\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 RDD\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate() \\\n",
    "    .sparkContext\n",
    "\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    # Use StringIO to treat the line as a file-like object\n",
    "    f = StringIO(line)\n",
    "    # Use csv.reader to correctly parse the CSV line\n",
    "    reader = csv.reader(f)\n",
    "    return next(reader) \n",
    "def help1(data):\n",
    "    try:\n",
    "        age=int(data)\n",
    "        if age<18 and age>0:\n",
    "            return \"child\"\n",
    "        if age<25:\n",
    "            return \"young adult\"\n",
    "        if age<65 :\n",
    "            return \"adult\"\n",
    "        if age>64:\n",
    "            return \"old\"\n",
    "        else:\n",
    "            return \"no individual victim\"\n",
    "    except:\n",
    "        return \"error\"\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "rdd1  = sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\")\\\n",
    ".map(parse_csv_line)\n",
    "\n",
    "rdd2= sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\")\\\n",
    ".map(parse_csv_line)\n",
    "\n",
    "header1 = rdd1.first()\n",
    "header2 = rdd2.first()\n",
    "\n",
    "# Filter out the header\n",
    "rdd1_data = rdd1.filter(lambda line: line != header1)\n",
    "rdd2_data = rdd2.filter(lambda line: line != header2)\n",
    "\n",
    "crime_data = rdd1_data.union(rdd2_data) \\\n",
    ".filter(lambda pair: pair[9].find(\"AGGRAVATED\") != -1 ) \\\n",
    ".map(lambda data: (help1(data[11]),1)) \\\n",
    ".reduceByKey(lambda a, b: a + b) \\\n",
    ".sortBy( lambda pair : pair[1], ascending=False )\n",
    "\n",
    "print(crime_data.collect())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e904bbc1-6e1b-46bc-b8ce-705efc077b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|  age_group| count|\n",
      "+-----------+------+\n",
      "|      adult|121093|\n",
      "|young adult| 38703|\n",
      "|      child| 10830|\n",
      "|        old|  5985|\n",
      "+-----------+------+\n",
      "\n",
      "Time taken: 2.37 seconds"
     ]
    }
   ],
   "source": [
    "####query 1 dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 Dataframe\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "\n",
    "def age_group(age_str):\n",
    "    try:\n",
    "        age=int(age_str)\n",
    "        if age<18 and age>0:\n",
    "            return \"child\"\n",
    "        if age<25:\n",
    "            return \"young adult\"\n",
    "        if age<65 :\n",
    "            return \"adult\"\n",
    "        if age>64:\n",
    "            return \"old\"\n",
    "        else:\n",
    "            return \"no individual victim\"\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "\n",
    "age_udf=udf(age_group,StringType())\n",
    "dataframe=dataframe1.union(dataframe2)\\\n",
    ".filter(col(\"Crm Cd Desc\").contains(\"AGGRAVATED\"))\\\n",
    ".withColumn(\"age_group\",age_udf(col(\"Vict Age\")))\\\n",
    ".groupBy(\"age_group\").agg(F.count(\"*\").alias(\"count\"))\\\n",
    ".orderBy(\"count\",ascending=False)\n",
    "\n",
    "\n",
    "dataframe.show()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82388c6c-dc7d-4ed6-b1a9-8ddcc8b9461e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------------+---+\n",
      "|year|   precinct|   closed_case_rate|  #|\n",
      "+----+-----------+-------------------+---+\n",
      "|2010|    Rampart|0.32947355855318133|  1|\n",
      "|2010|    Olympic|0.31962706191728424|  2|\n",
      "|2010|     Harbor| 0.2963203463203463|  3|\n",
      "|2011|    Olympic|0.35212167689161555|  1|\n",
      "|2011|    Rampart|0.32511779630300836|  2|\n",
      "|2011|     Harbor| 0.2865220520201501|  3|\n",
      "|2012|    Olympic| 0.3441481831052383|  1|\n",
      "|2012|    Rampart|  0.329464181029429|  2|\n",
      "|2012|     Harbor| 0.2981513327601032|  3|\n",
      "|2013|    Olympic| 0.3352812271731191|  1|\n",
      "|2013|    Rampart| 0.3208287360549221|  2|\n",
      "|2013|     Harbor| 0.2916422459266206|  3|\n",
      "|2014|   Van Nuys| 0.3180567315834039|  1|\n",
      "|2014|West Valley| 0.3131198995605775|  2|\n",
      "|2014|    Mission| 0.3116279069767442|  3|\n",
      "|2015|   Van Nuys| 0.3264134698172773|  1|\n",
      "|2015|West Valley| 0.3027597402597403|  2|\n",
      "|2015|    Mission|0.30179460678380154|  3|\n",
      "|2016|   Van Nuys|0.31880755720117726|  1|\n",
      "|2016|West Valley| 0.3154798761609907|  2|\n",
      "|2016|   Foothill| 0.2987029184335246|  3|\n",
      "|2017|   Van Nuys|0.32020342117429496|  1|\n",
      "|2017|    Mission| 0.3103892518634398|  2|\n",
      "|2017|   Foothill|0.30469226081657524|  3|\n",
      "+----+-----------+-------------------+---+\n",
      "only showing top 24 rows\n",
      "\n",
      "Time taken: 9.16 seconds"
     ]
    }
   ],
   "source": [
    "####query2 dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col,count,when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 Dataframe\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"Year\").orderBy(F.desc(\"closed_case_rate\"))\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "\n",
    "\n",
    "\n",
    "dataframe=dataframe1.union(dataframe2)\\\n",
    ".withColumn(\"year\",col(\"Date Rptd\").substr(7,4))\\\n",
    ".select(\"year\",\"AREA NAME\",\"Status\")\\\n",
    ".groupBy(\"year\",\"AREA NAME\").agg((count(when(col(\"Status\") != \"IC\", 1)) / count(\"*\") ).alias(\"closed_case_rate\"))\\\n",
    ".withColumn(\"#\", F.row_number().over(window_spec) )\\\n",
    ".filter(col(\"#\") <= 3)\\\n",
    ".withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "dataframe.show(24)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdae980b-ed68-4d53-b0c1-700edc75a0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------------+---+\n",
      "|year|   precinct|   closed_case_rate|  #|\n",
      "+----+-----------+-------------------+---+\n",
      "|2010|    Rampart|0.32947355855318133|  1|\n",
      "|2010|    Olympic|0.31962706191728424|  2|\n",
      "|2010|     Harbor| 0.2963203463203463|  3|\n",
      "|2011|    Olympic|0.35212167689161555|  1|\n",
      "|2011|    Rampart|0.32511779630300836|  2|\n",
      "|2011|     Harbor| 0.2865220520201501|  3|\n",
      "|2012|    Olympic| 0.3441481831052383|  1|\n",
      "|2012|    Rampart|  0.329464181029429|  2|\n",
      "|2012|     Harbor| 0.2981513327601032|  3|\n",
      "|2013|    Olympic| 0.3352812271731191|  1|\n",
      "|2013|    Rampart| 0.3208287360549221|  2|\n",
      "|2013|     Harbor| 0.2916422459266206|  3|\n",
      "|2014|   Van Nuys| 0.3180567315834039|  1|\n",
      "|2014|West Valley| 0.3131198995605775|  2|\n",
      "|2014|    Mission| 0.3116279069767442|  3|\n",
      "|2015|   Van Nuys| 0.3264134698172773|  1|\n",
      "|2015|West Valley| 0.3027597402597403|  2|\n",
      "|2015|    Mission|0.30179460678380154|  3|\n",
      "|2016|   Van Nuys|0.31880755720117726|  1|\n",
      "|2016|West Valley| 0.3154798761609907|  2|\n",
      "|2016|   Foothill| 0.2987029184335246|  3|\n",
      "|2017|   Van Nuys|0.32020342117429496|  1|\n",
      "|2017|    Mission| 0.3103892518634398|  2|\n",
      "|2017|   Foothill|0.30469226081657524|  3|\n",
      "+----+-----------+-------------------+---+\n",
      "only showing top 24 rows\n",
      "\n",
      "Time taken: 18.17 seconds"
     ]
    }
   ],
   "source": [
    "###query2 spark sql api\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col,count,when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 SQL API\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "\n",
    "dataframe=dataframe1.union(dataframe2)\n",
    "\n",
    "dataframe.createOrReplaceTempView(\"Dataset\")\n",
    "query= \"\"\"\n",
    "    WITH extracted_data AS (\n",
    "        SELECT \n",
    "            substr(`Date Rptd`, 7, 4) AS year,\n",
    "            `AREA NAME` AS precinct,\n",
    "            Status\n",
    "        FROM Dataset\n",
    "    ),\n",
    "    aggregated_data AS (\n",
    "        SELECT\n",
    "            year,\n",
    "            precinct,\n",
    "            COUNT(CASE WHEN Status != 'IC' THEN 1 END)  / COUNT(*) AS closed_case_rate\n",
    "        FROM extracted_data\n",
    "        GROUP BY year, precinct\n",
    "    ),\n",
    "    ranked_data AS (\n",
    "        SELECT\n",
    "            year,\n",
    "            precinct,\n",
    "            closed_case_rate,\n",
    "            ROW_NUMBER() OVER (PARTITION BY year ORDER BY closed_case_rate DESC) AS `#`\n",
    "        FROM aggregated_data\n",
    "    )\n",
    "    SELECT \n",
    "        year,\n",
    "        precinct,\n",
    "        closed_case_rate,\n",
    "        `#`\n",
    "    FROM ranked_data\n",
    "    WHERE `#` <= 3\n",
    "\"\"\"\n",
    "res=spark.sql(query)\n",
    "res.show(24)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a65462-35a1-4add-9f18-eeab06075f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####2b\n",
    "####make parquet dataset\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col,count,when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2b write parquet\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "dataframe=dataframe1.union(dataframe2)\n",
    "\n",
    "dataframe.coalesce(1).write.mode(\"overwrite\").parquet(\"s3://groups-bucket-dblab-905418150721/group35/main_dataset_parquet\") ##coalesce gia 1 file\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e259e26a-6aae-4f07-96f7-0d6614118af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------------+---+\n",
      "|year|   precinct|   closed_case_rate|  #|\n",
      "+----+-----------+-------------------+---+\n",
      "|2010|    Rampart|0.32947355855318133|  1|\n",
      "|2010|    Olympic|0.31962706191728424|  2|\n",
      "|2010|     Harbor| 0.2963203463203463|  3|\n",
      "|2011|    Olympic|0.35212167689161555|  1|\n",
      "|2011|    Rampart|0.32511779630300836|  2|\n",
      "|2011|     Harbor| 0.2865220520201501|  3|\n",
      "|2012|    Olympic| 0.3441481831052383|  1|\n",
      "|2012|    Rampart|  0.329464181029429|  2|\n",
      "|2012|     Harbor| 0.2981513327601032|  3|\n",
      "|2013|    Olympic| 0.3352812271731191|  1|\n",
      "|2013|    Rampart| 0.3208287360549221|  2|\n",
      "|2013|     Harbor| 0.2916422459266206|  3|\n",
      "|2014|   Van Nuys| 0.3180567315834039|  1|\n",
      "|2014|West Valley| 0.3131198995605775|  2|\n",
      "|2014|    Mission| 0.3116279069767442|  3|\n",
      "|2015|   Van Nuys| 0.3264134698172773|  1|\n",
      "|2015|West Valley| 0.3027597402597403|  2|\n",
      "|2015|    Mission|0.30179460678380154|  3|\n",
      "|2016|   Van Nuys|0.31880755720117726|  1|\n",
      "|2016|West Valley| 0.3154798761609907|  2|\n",
      "|2016|   Foothill| 0.2987029184335246|  3|\n",
      "|2017|   Van Nuys|0.32020342117429496|  1|\n",
      "|2017|    Mission| 0.3103892518634398|  2|\n",
      "|2017|   Foothill|0.30469226081657524|  3|\n",
      "|2018|   Foothill|  0.307089506550753|  1|\n",
      "|2018|    Mission|0.30690661478599224|  2|\n",
      "|2018|   Van Nuys|0.29078685730517945|  3|\n",
      "|2019|West Valley| 0.3077447195094254|  1|\n",
      "|2019|    Mission|0.30748519116855144|  2|\n",
      "|2019|   Foothill| 0.2953842186694172|  3|\n",
      "|2020|West Valley|0.31144886009717204|  1|\n",
      "|2020|    Mission| 0.3038777908343126|  2|\n",
      "|2020|     Harbor| 0.2988065750956992|  3|\n",
      "|2021|    Mission| 0.3091391367253436|  1|\n",
      "|2021|West Valley| 0.2887750349324639|  2|\n",
      "|2021|   Foothill|0.28464788732394364|  3|\n",
      "|2022|West Valley| 0.2664366494153728|  1|\n",
      "|2022|     Harbor| 0.2633405639913232|  2|\n",
      "|2022|    Topanga| 0.2627340236376948|  3|\n",
      "|2023|   Foothill|  0.268215994531784|  1|\n",
      "|2023|    Topanga|0.26407806464728606|  2|\n",
      "|2023|    Mission|0.25941195616795054|  3|\n",
      "|2024|N Hollywood|0.19514978601997146|  1|\n",
      "|2024|   Foothill|0.18531827515400412|  2|\n",
      "|2024|77th Street|0.17349137931034483|  3|\n",
      "+----+-----------+-------------------+---+\n",
      "\n",
      "Time taken: 1.76 seconds"
     ]
    }
   ],
   "source": [
    "####2b test parquet file on 2a query dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col,count,when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2b test parquet for 2b Dataframe\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "dataframe = spark.read.parquet(\"s3://groups-bucket-dblab-905418150721/group35/main_dataset_parquet\")\n",
    "\n",
    "dataframe=dataframe.withColumn(\"year\",col(\"Date Rptd\").substr(7,4))\\\n",
    ".select(\"year\",\"AREA NAME\",\"Status\")\\\n",
    ".groupBy(\"year\",\"AREA NAME\").agg((count(when(col(\"Status\") != \"IC\", 1)) / count(\"*\") ).alias(\"closed_case_rate\"))\\\n",
    ".withColumn(\"#\", F.row_number().over(window_spec) )\\\n",
    ".filter(col(\"#\") <= 3)\\\n",
    ".withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "dataframe.show(60)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb0b5b8-5e92-4bcd-b15a-1d04537696c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------------+-----------------+\n",
      "|                COMM|total_population|comm_total_income|   average_income|\n",
      "+--------------------+----------------+-----------------+-----------------+\n",
      "|         Culver City|           38883|    2.905977048E9|74736.44132397191|\n",
      "|     North Lancaster|            1101|       4.438881E7|40316.81198910082|\n",
      "|Rosewood/East Gar...|            1164|      6.2048184E7|          53306.0|\n",
      "+--------------------+----------------+-----------------+-----------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "####query 3\n",
    "\n",
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GeoJSON read\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "# Read the file from s3\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "# Formatting magic\n",
    "blocks_census = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "census=blocks_census.select(\"COMM\",\"POP_2010\",\"ZCTA10\").na.fill({\"POP_2010\": 0}).groupBy(\"COMM\",\"ZCTA10\").agg(F.sum(\"POP_2010\").alias(\"POP_2010\"))\n",
    "\n",
    "\n",
    "income= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True)\n",
    "\n",
    "res1= income.withColumn( \"Estimated Median Income\", F.regexp_replace(col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"float\"))\\\n",
    ".join(census,census[\"ZCTA10\"]==income[\"Zip Code\"])\\\n",
    ".withColumn(\"total_income\",col(\"Estimated Median Income\")*col(\"POP_2010\") )\\\n",
    ".groupBy(\"COMM\").agg(\n",
    "                    F.sum(\"POP_2010\").alias(\"total_population\"),\n",
    "                    F.sum(\"total_income\").alias(\"comm_total_income\"))\\\n",
    ".withColumn(\"average_income\", col(\"comm_total_income\")/col(\"total_population\"))\n",
    "\n",
    "\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "dataframe=dataframe1.union(dataframe2)\n",
    "\n",
    "res2=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f8a33db-4d59-4b6a-8b28-9c7313a7f92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|ZCTA10|sum(POP_2010)|\n",
      "+------+-------------+\n",
      "| 90807|        31481|\n",
      "| 91326|        33708|\n",
      "| 90094|         5464|\n",
      "+------+-------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "# # # # income= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True)\n",
    "\n",
    "# # # # income.filter(col(\"Community\").contains(\"Antelope\")).show(3)\n",
    "\n",
    "# res=income.join(blocks_census,blocks_census[\"ZCTA10\"]==income[\"Zip Code\"])\n",
    "# print(res.select(\"ZCTA10\").distinct().count())\n",
    "\n",
    "# # print(res.select(\"Community\").distinct().count())\n",
    "# # # res.show(3)\n",
    "# # # print(res.count())\n",
    "# # # print(income.select(\"Community\").distinct().count())\n",
    "# # # print(census.select(\"COMM\").distinct().count())\n",
    "# print(blocks_census.select(\"COMM\").distinct().count())\n",
    "# print(blocks_census.select(\"ZCTA10\").distinct().count())\n",
    "\n",
    "# blocks_census.show(3)\n",
    "census.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4428d4-e7a0-4910-a362-8d542615e8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------------+\n",
      "|Zip Code|           Community|Estimated Median Income|\n",
      "+--------+--------------------+-----------------------+\n",
      "|   90001|Los Angeles (Sout...|                $33,887|\n",
      "|   90002|Los Angeles (Sout...|                $30,413|\n",
      "|   90003|Los Angeles (Sout...|                $30,805|\n",
      "|   90004|Los Angeles (Hanc...|                $40,612|\n",
      "|   90005|Los Angeles (Hanc...|                $31,142|\n",
      "|   90006|Los Angeles (Byza...|                $31,521|\n",
      "|   90007|Los Angeles (Sout...|                $22,304|\n",
      "|   90008|Los Angeles (Bald...|                $36,564|\n",
      "|   90010|Los Angeles (Hanc...|                $45,786|\n",
      "|   90011|Los Angeles (Sout...|                $30,251|\n",
      "+--------+--------------------+-----------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "income.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a861ee-b38a-4faa-9f73-77318b90adfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------------+------------------+\n",
      "|                COMM|total_population|comm_total_income|    average_income|\n",
      "+--------------------+----------------+-----------------+------------------+\n",
      "|         Culver City|           38883|    2.905977048E9| 74736.44132397191|\n",
      "|     North Lancaster|            1101|       4.438881E7| 40316.81198910082|\n",
      "|Rosewood/East Gar...|            1164|      6.2048184E7|           53306.0|\n",
      "|East Rancho Domin...|           15135|     6.35064576E8|41959.998414271555|\n",
      "|      Toluca Terrace|            1301|        6.30972E7| 48499.00076863951|\n",
      "|        Elysian Park|            5267|     1.92298904E8| 36510.13935826846|\n",
      "|            Longwood|            4210|     1.61369296E8| 38329.99904988123|\n",
      "|         Pico Rivera|           62942|    3.509822933E9| 55762.81231927806|\n",
      "|              Malibu|           12645|    1.563922097E9|123679.09031237643|\n",
      "|       Green Meadows|           19821|      6.0605866E8| 30576.59351193179|\n",
      "|    Hacienda Heights|           53594|    4.179868628E9| 77991.35403216779|\n",
      "|    Cadillac-Corning|            6665|     3.90970474E8| 58660.23615903976|\n",
      "|  West Puente Valley|            9657|     5.66296128E8|58640.999068033554|\n",
      "|            Mid-city|           14339|     6.67781568E8| 46570.99993026013|\n",
      "|          Montebello|           62500|    2.868084216E9|      45889.347456|\n",
      "|          Lake Manor|            1600|     1.13507096E8|         70941.935|\n",
      "|    Hawaiian Gardens|           14254|      5.3824215E8|37760.779430335344|\n",
      "|    Westlake Village|            8270|     8.65722344E8|104682.26650544135|\n",
      "|     Lincoln Heights|           31144|    1.136865072E9| 36503.50218340611|\n",
      "|            Van Nuys|           86019|    3.677772964E9| 42755.35595624222|\n",
      "|    Placerita Canyon|             113|        6729037.0|           59549.0|\n",
      "|              Carson|           91714|    6.519615092E9| 71086.36731578603|\n",
      "|     Bandini Islands|               0|              0.0|              NULL|\n",
      "|     Rowland Heights|           49042|    2.994956189E9| 61069.20984054484|\n",
      "|        Agoura Hills|           20330|    2.326097664E9|114417.00265617315|\n",
      "|            Glendale|          191719|  1.1191119701E10|58372.512380097956|\n",
      "|Northeast San Gab...|           22680|    1.541302848E9| 67958.67936507937|\n",
      "|      Gramercy Place|           10361|     4.06866112E8|39269.000289547344|\n",
      "|      Bouquet Canyon|            1072|     1.12632096E8|105067.25373134328|\n",
      "|   Faircrest Heights|            3443|     1.80841214E8|52524.314260819054|\n",
      "|         Sun Village|            5833|     3.03081206E8| 51959.74729984571|\n",
      "|       Boyle Heights|           82536|    2.678204032E9| 32448.91964718426|\n",
      "|        Hidden Hills|            1856|     2.12860928E8|          114688.0|\n",
      "|    Lafayette Square|            4358|     2.02841036E8| 46544.52409362093|\n",
      "|       Granada Hills|           55172|    4.430550432E9| 80304.32886246647|\n",
      "|         North Hills|           56375|    3.178409504E9| 56379.76947228381|\n",
      "|West Antelope Valley|            1509|      1.0268772E8| 68050.17892644135|\n",
      "|Santa Monica Moun...|           17610|    1.949783875E9|110720.26547416241|\n",
      "|              Saugus|             763|       8.116336E7|106373.99737876802|\n",
      "|         Lake Hughes|             749|         4.1195E7|           55000.0|\n",
      "|          Northridge|           62037|    3.779794409E9| 60928.06565436756|\n",
      "|         Signal Hill|           11016|     7.26213582E8| 65923.52777777778|\n",
      "|     Wilshire Center|           47295|    1.800387904E9| 38067.19323395708|\n",
      "|            Glendora|           50694|    3.858422272E9| 76112.01073105299|\n",
      "|      Jefferson Park|            7612|     2.57772768E8|           33864.0|\n",
      "|      Vermont Square|            7045|     2.11480352E8|30018.502767920512|\n",
      "|Saugus/Canyon Cou...|             419|      4.4570704E7|106373.99522673032|\n",
      "|  Cloverdale/Cochran|           14032|      5.7491456E8| 40971.67616875713|\n",
      "| Rancho Palos Verdes|           41643|    4.946771968E9|118789.99995197271|\n",
      "|     Adams-Normandie|            7842|     2.20951456E8|28175.396072430503|\n",
      "+--------------------+----------------+-----------------+------------------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "res.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e63b7-6621-4057-8df8-350d6b94a546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
