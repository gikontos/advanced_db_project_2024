{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c8305e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('adult', 121093), ('young adult', 38703), ('child', 10830), ('old', 5985)]\n",
      "Time taken: 26.51 seconds"
     ]
    }
   ],
   "source": [
    "# Query 1 RDD\n",
    "\n",
    "import csv,time\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 RDD\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate() \\\n",
    "    .sparkContext\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    f = StringIO(line)\n",
    "    reader = csv.reader(f)\n",
    "    return next(reader) \n",
    "\n",
    "def help1(data):\n",
    "    try:\n",
    "        age=int(data)\n",
    "        if age<18 and age>0:\n",
    "            return \"child\"\n",
    "        if age<25:\n",
    "            return \"young adult\"\n",
    "        if age<65 :\n",
    "            return \"adult\"\n",
    "        if age>64:\n",
    "            return \"old\"\n",
    "        else:\n",
    "            return \"no individual victim\"\n",
    "    except:\n",
    "        return \"error\"\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "rdd1  = sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\")\\\n",
    ".map(parse_csv_line)\n",
    "\n",
    "rdd2= sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\")\\\n",
    ".map(parse_csv_line)\n",
    "\n",
    "header1 = rdd1.first()\n",
    "header2 = rdd2.first()\n",
    "\n",
    "# Filter out the header\n",
    "rdd1_data = rdd1.filter(lambda line: line != header1)\n",
    "rdd2_data = rdd2.filter(lambda line: line != header2)\n",
    "\n",
    "crime_data = rdd1_data.union(rdd2_data) \\\n",
    ".filter(lambda pair: pair[9].find(\"AGGRAVATED\") != -1 ) \\\n",
    ".map(lambda data: (help1(data[11]), 1)) \\\n",
    ".reduceByKey(lambda a, b: a + b) \\\n",
    ".sortBy( lambda pair : pair[1], ascending=False )\n",
    "\n",
    "print(crime_data.collect())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59e0ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|  age_group| count|\n",
      "+-----------+------+\n",
      "|      adult|121093|\n",
      "|young adult| 38703|\n",
      "|      child| 10830|\n",
      "|        old|  5985|\n",
      "+-----------+------+\n",
      "\n",
      "Time taken: 18.34 seconds"
     ]
    }
   ],
   "source": [
    "####query 1 dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 Dataframe\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "\n",
    "def age_group(age_str):\n",
    "    try:\n",
    "        age=int(age_str)\n",
    "        if age<18 and age>0:\n",
    "            return \"child\"\n",
    "        if age<25:\n",
    "            return \"young adult\"\n",
    "        if age<65 :\n",
    "            return \"adult\"\n",
    "        if age>64:\n",
    "            return \"old\"\n",
    "        else:\n",
    "            return \"no individual victim\"\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "\n",
    "age_udf=udf(age_group,StringType())\n",
    "dataframe=dataframe1.union(dataframe2)\\\n",
    ".filter(col(\"Crm Cd Desc\").contains(\"AGGRAVATED\"))\\\n",
    ".withColumn(\"age_group\",age_udf(col(\"Vict Age\")))\\\n",
    ".groupBy(\"age_group\").agg(F.count(\"*\").alias(\"count\"))\\\n",
    ".orderBy(\"count\",ascending=False)\n",
    "\n",
    "\n",
    "dataframe.show()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45b2cff-3001-4b85-acc0-0b2308ff06e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------------+---+\n",
      "|year|   precinct|   closed_case_rate|  #|\n",
      "+----+-----------+-------------------+---+\n",
      "|2010|    Rampart|0.32947355855318133|  1|\n",
      "|2010|    Olympic|0.31962706191728424|  2|\n",
      "|2010|     Harbor| 0.2963203463203463|  3|\n",
      "|2011|    Olympic|0.35212167689161555|  1|\n",
      "|2011|    Rampart|0.32511779630300836|  2|\n",
      "|2011|     Harbor| 0.2865220520201501|  3|\n",
      "|2012|    Olympic| 0.3441481831052383|  1|\n",
      "|2012|    Rampart|  0.329464181029429|  2|\n",
      "|2012|     Harbor| 0.2981513327601032|  3|\n",
      "|2013|    Olympic| 0.3352812271731191|  1|\n",
      "|2013|    Rampart| 0.3208287360549221|  2|\n",
      "|2013|     Harbor| 0.2916422459266206|  3|\n",
      "|2014|   Van Nuys| 0.3180567315834039|  1|\n",
      "|2014|West Valley| 0.3131198995605775|  2|\n",
      "|2014|    Mission| 0.3116279069767442|  3|\n",
      "|2015|   Van Nuys| 0.3264134698172773|  1|\n",
      "|2015|West Valley| 0.3027597402597403|  2|\n",
      "|2015|    Mission|0.30179460678380154|  3|\n",
      "|2016|   Van Nuys|0.31880755720117726|  1|\n",
      "|2016|West Valley| 0.3154798761609907|  2|\n",
      "|2016|   Foothill| 0.2987029184335246|  3|\n",
      "|2017|   Van Nuys|0.32020342117429496|  1|\n",
      "|2017|    Mission| 0.3103892518634398|  2|\n",
      "|2017|   Foothill|0.30469226081657524|  3|\n",
      "+----+-----------+-------------------+---+\n",
      "only showing top 24 rows\n",
      "\n",
      "Time taken: 16.15 seconds"
     ]
    }
   ],
   "source": [
    "#query 2 a\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import udf, col,count,when\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 Dataframe\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"Year\").orderBy(F.desc(\"closed_case_rate\"))\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "\n",
    "dataframe1= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True)\n",
    "dataframe2= spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\",header=True)\n",
    "\n",
    "\n",
    "\n",
    "dataframe=dataframe1.union(dataframe2)\\\n",
    ".withColumn(\"year\",col(\"Date Rptd\").substr(7,4))\\\n",
    ".select(\"year\",\"AREA NAME\",\"Status\")\\\n",
    ".groupBy(\"year\",\"AREA NAME\").agg((count(when(col(\"Status\") != \"IC\", 1)) / count(\"*\") ).alias(\"closed_case_rate\"))\\\n",
    ".withColumn(\"#\", F.row_number().over(window_spec) )\\\n",
    ".filter(col(\"#\") <= 3)\\\n",
    ".withColumnRenamed(\"AREA NAME\", \"precinct\")\n",
    "\n",
    "dataframe.show(24)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899b63d-5913-44ab-bcb2-c5debeecf66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "python3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
